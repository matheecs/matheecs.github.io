---
layout: post
title: "å¼ºåŒ–å­¦ä¹ ç¬”è®°"
categories: study
author: "Jixiang Zhang"
---

å¼ºåŒ–å­¦ä¹ ä¾èµ– GPU åŠ é€Ÿè®­ç»ƒå‡ºç¦»çº¿ Policyï¼›é‚£ä¹ˆåŸºäºæ¨¡å‹çš„ç®—æ³•èƒ½å¦ç”¨ GPU å®ç°å¿«é€Ÿçš„åœ¨çº¿è§„åˆ’ç®—æ³•ï¼Ÿ

## æ„å»ºå¹¶è¡Œä»¿çœŸç¯å¢ƒ `create_sim`

æ­¥éª¤ï¼š

1. gym.create_sim
2. åˆ›å»ºåœ°å½¢
3. `_create_envs`
   1. loads the robot URDF/MJCF asset,
   2. For each environment:
      1. creates the environment
      2. calls DOF and Rigid shape properties callbacks
         * `_process_rigid_shape_props`
         * `_process_dof_props`
         * `_process_rigid_body_props`
      3. create actor with these properties and add them to the env
   3. Store indices of different bodies of the robot

<p align="center"><img src="{{site.baseurl}}/images/rl.jpg" width="500"/></p>

## è®­ç»ƒç®—æ³•ä¸ç¯å¢ƒäº¤äº’

* PPO. -- [actions] --> Envs.step()
* Envs -- [obs,reward,reset] --> PPO

## å®ç°åŸç†

<p align="center">  <img src="{{site.baseurl}}/images/classes.png" width="500"/></p>

### class `BaseTask`

* get_observations
* get_privileged_observations
* render
* reset é‡ç½®æ‰€æœ‰å¹¶è¡Œä»¿çœŸç¯å¢ƒ
* reset_idx **NotImplementedError** é‡ç½®å•ä¸ªç¯å¢ƒ
  1. æ›´æ–°è¯¾ç¨‹
  2. é‡ç½®æœºå™¨äººçŠ¶æ€
  3. é‡æ–°é‡‡ç”¨æŒ‡ä»¤
  4. é‡ç½®ç¼“å­˜
  5. é‡ç½®é‡è®¾æŒ‡ä»¤çš„æ­¥æ€ç”Ÿæˆå™¨çš„åˆå§‹è®¡æ•°å€¼
  6. æ›´æ–°è§‚æµ‹é‡ç¼“å­˜
* step **NotImplementedError**
  1. PD: Action > Torque
  2. ç‰©ç†ä»¿çœŸ `gym.simulate(sim)`
  3. `post_physics_step`
     1. `_post_physics_step_callback`
     2. `check_termination`
     3. `compute_reward`
     4. `reset_idx`
     5. `compute_observations`
  4. è¿”å› **è§‚æµ‹é‡+ç‰¹æƒè§‚æµ‹é‡+å¥–åŠ±+é‡ç½®ä¸å¦+å…¶ä»–ä¿¡æ¯**

---

æ€»ç»“æ¥è¯´ï¼Œæ­£å¥–åŠ±ä¸è´Ÿå¥–åŠ±çš„ä¸»è¦åŒºåˆ«åœ¨äºå®ƒä»¬å¯¹æ™ºèƒ½ä½“è¡Œä¸ºçš„å¼•å¯¼æ–¹å¼ä¸åŒï¼šğŸ†**æ­£å¥–åŠ±** $\exp(-x)$ é¼“åŠ±è¡Œä¸ºé‡å¤ï¼Œâ›”**è´Ÿå¥–åŠ±**åˆ™æŠ‘åˆ¶è¡Œä¸ºã€‚é€šè¿‡æ­£è´Ÿå¥–åŠ±çš„å·§å¦™è®¾è®¡ï¼Œæ™ºèƒ½ä½“å¯ä»¥é€æ­¥å­¦ä¼šæœ€ä¼˜ç­–ç•¥ã€‚

### class `LeggedRobot`

* _compute_torques ç”¨ Action + PD ç®—åŠ›çŸ©
* _create_envs æ ¹æ® URDF åˆ›å»ºå¹¶è¡Œä»¿çœŸç¯å¢ƒ
* _create_ground_plane
* _create_heightfield
* _create_trimesh
* _draw_debug_vis
* _get_env_origins
* _get_heights
* _get_noise_scale_vec ç”Ÿæˆè§‚æµ‹é‡å™ªå£°
* _init_buffers åˆå§‹åŒ– Tensor ç¼“å­˜å˜é‡
* _init_height_points
* _parse_cfg
* _post_physics_step_callback æŒ‡ä»¤é‡‡æ · è®¡ç®—åœ°å½¢é«˜åº¦å’Œå¤–éƒ¨æ‰°åŠ¨
* _prepare_reward_function
* _process_dof_props è·å–éæµ®åŠ¨åŸºå…³èŠ‚ Limit ä¿¡æ¯
* _process_rigid_body_props åˆšä½“è´¨é‡ è´¨å¿ƒ æƒ¯é‡éšæœºåŒ–
* _process_rigid_shape_props æ‘©æ“¦ç³»æ•°éšæœºåŒ–
* _push_robots æµ®åŠ¨åŸºé€Ÿåº¦éšæœºåŒ–
* _resample_commands æŒ‡ä»¤éšæœºåŒ–
* _reset_dofs éæµ®åŠ¨åŸºå…³èŠ‚ä½ç½®é€Ÿåº¦éšæœºåŒ–
* _reset_root_states æµ®åŠ¨åŸºä½ç½®é€Ÿåº¦éšæœºåŒ–
* _update_terrain_curriculum æ›´æ–°åœ°å½¢è¯¾ç¨‹
* check_termination æ£€æŸ¥æ¯ä¸ªç¯å¢ƒç»ˆæ­¢æ¡ä»¶
* compute_observations **override** è®¡ç®—è§‚æµ‹é‡
* compute_reward è®¡ç®—å¥–åŠ±
* create_sim æ„é€ å¹¶è¡Œä»¿çœŸç¯å¢ƒ
* post_physics_step æ£€æŸ¥ç»ˆæ­¢æ¡ä»¶ > è®¡ç®—å¥–åŠ± > é‡ç½® > è®¡ç®—è§‚æµ‹é‡
* reset_idx **override** é‡ç½®å•ä¸ªç¯å¢ƒ
* set_camera
* step **override** æ‰§è¡Œ Action > ç‰©ç†ä»¿çœŸ > post_physics_step
* update_command_curriculum æ›´æ–°æŒ‡ä»¤è¯¾ç¨‹
* â›” _reward_lin_vel_z æƒ©ç½šæµ®åŠ¨åŸºé‡åŠ›æ–¹å‘çº¿é€Ÿåº¦
* â›” _reward_ang_vel_xy æƒ©ç½šæµ®åŠ¨åŸºæ°´å¹³æ–¹å‘è§’é€Ÿåº¦
* â›” _reward_orientation æƒ©ç½šæµ®åŠ¨åŸºå§¿æ€
* â›” _reward_base_height æƒ©ç½šæµ®åŠ¨åŸºé«˜åº¦
* â›” _reward_torques æƒ©ç½šå…³èŠ‚è¾“å‡ºåŠ›çŸ©
* â›” _reward_dof_vel æƒ©ç½šå…³èŠ‚é€Ÿåº¦
* â›” _reward_dof_acc æƒ©ç½šå…³èŠ‚åŠ é€Ÿåº¦
* â›” _reward_action_rate æƒ©ç½š action å˜åŒ–ç‡
* â›” _reward_collision æƒ©ç½šæ‰€é€‰åˆšä½“ç¢°æ’
* â›” _reward_termination ç»ˆæ­¢æ—¶çš„å¥–åŠ±
* â›” _reward_dof_pos_limits æƒ©ç½šå…³èŠ‚ä½ç½®è¶‹è¿‘æå€¼
* â›” _reward_dof_vel_limits æƒ©ç½šå…³èŠ‚é€Ÿåº¦è¶‹è¿‘æå€¼
* â›” _reward_torque_limits æƒ©ç½šå…³èŠ‚è¾“å‡ºåŠ›çŸ©è¶‹è¿‘æå€¼
* ğŸ† _reward_tracking_lin_vel **exp** å¥–åŠ±çº¿é€Ÿåº¦è·Ÿè¸ª
* ğŸ† _reward_tracking_ang_vel **exp** å¥–åŠ±è§’é€Ÿåº¦è·Ÿè¸ª
* â›” _reward_feet_air_time å¥–åŠ±è¶³ç«¯æŒä¹…è…¾ç©º
* â›” _reward_stumble æƒ©ç½šè¶³ç«¯ä¸ç«–ç›´è¡¨é¢æ¥è§¦
* â›” _reward_stand_still æƒ©ç½šå…³èŠ‚è¿åŠ¨(ç«™ç«‹æ—¶)
* â›” _reward_feet_contact_forces æƒ©ç½šè¶³ç«¯è¿‡å¤§çš„æ¥è§¦åŠ›

### class `ZqSA01`

* _get_noise_scale_vec **override** ç”Ÿæˆè§‚æµ‹é‡å™ªå£°
* _refresh_gym_tensors æ›´æ–°ä»¿çœŸå™¨ Tensor
* _resample_commands **override** æŒ‡ä»¤éšæœºåŒ–
* _reset_dofs **override** éæµ®åŠ¨åŸºå…³èŠ‚ä½ç½®é€Ÿåº¦éšæœºåŒ–
* _reset_root_states **override** æµ®åŠ¨åŸºä½ç½®é€Ÿåº¦éšæœºåŒ–
* check_termination **override** æ£€æŸ¥æ¯ä¸ªç¯å¢ƒç»ˆæ­¢æ¡ä»¶
* compute_observations **override** è®¡ç®—è§‚æµ‹é‡
* compute_reference_states è®¡ç®—å‚è€ƒçŠ¶æ€
* create_sim **override** æ„é€ å¹¶è¡Œä»¿çœŸç¯å¢ƒ
* reset_idx **override** é‡ç½®å•ä¸ªç¯å¢ƒ é‡ç½®é‡è®¾æŒ‡ä»¤çš„æ­¥æ€ç”Ÿæˆå™¨çš„åˆå§‹è®¡æ•°å€¼
* step **override** æ‰§è¡Œ Action > ç‰©ç†ä»¿çœŸ > post_physics_step
* â›” _reward_no_fly å¥–åŠ±å•è„šæ¥è§¦
* ğŸ† _reward_target_joint_pos_l **exp** å¥–åŠ±
* ğŸ† _reward_target_joint_pos_r **exp** å¥–åŠ±
* ğŸ† _reward_orientation **exp** å¥–åŠ±
* ğŸ† _reward_tracking_lin_x_vel **exp** å¥–åŠ±
* ğŸ† _reward_tracking_lin_y_vel **exp** å¥–åŠ±
* â›” _reward_action_smoothness æŒ‡ä»¤å¹³æ»‘é¡¹
* ğŸ† _reward_feet_distance **exp** å¥–åŠ±åŒè„šä¿æŒä¸€å®šè·ç¦»
* â›” _reward_ankle_action_rate æƒ©ç½š
* â›” _reward_ankle_dof_acc æƒ©ç½š
* ğŸ† _reward_target_ankle_pos **exp** å¥–åŠ±
* ğŸ† _reward_target_hip_roll_pos **exp** å¥–åŠ±

## å‚æ•°é…ç½®

### class `LeggedRobotCfg`

| XXX           | function |
| ------------- | -------- |
| env           | ç¯å¢ƒä¿¡æ¯ |
| terrian       | åœ°å½¢ä¿¡æ¯ |
| init_state    | åˆå§‹çŠ¶æ€ |
| control       | å…³èŠ‚æ§åˆ¶ |
| sim           | ä»¿çœŸå‚æ•° |
| viewer        | è§‚å¯Ÿè®¾ç½® |
| noise         | å™ªå£°å‚æ•° |
| normalization | ç¼©æ”¾å‚æ•° |
| commands      | æŒ‡ä»¤å‚æ•° |
| asset         | æœºå™¨æ¨¡å‹ |
| domain_rand   | åŸŸéšæœºåŒ– |
| rewards       | å¥–åŠ±å‚æ•° |

### class `LeggedRobotCfgPPO`

| XXX       | function    |
| --------- | ----------- |
| policy    | ç­–ç•¥ç½‘ç»œ    |
| runner    | ActorCritic |
| algorithm | ç®—æ³•å‚æ•°    |

**è®­ç»ƒæ—¥å¿—**

```bash
                     Learning iteration 20291/40000                     

                       Computation: 215205 steps/s (collection: 0.333s, learning 0.124s)
               Value function loss: 0.2949
                    Surrogate loss: -0.0028
             Mean action noise std: 0.51
                       Mean reward: 628.45
               Mean episode length: 1985.67
      Mean episode rew_action_rate: -1.6791
Mean episode rew_ankle_action_rate: -0.3818
    Mean episode rew_ankle_dof_acc: -0.0201
        Mean episode rew_collision: -0.0008
          Mean episode rew_dof_acc: -0.1378
   Mean episode rew_dof_pos_limits: -0.0000
Mean episode rew_feet_contact_forces: -0.2618
    Mean episode rew_feet_distance: 0.9603
        Mean episode rew_lin_vel_z: -0.0237
      Mean episode rew_orientation: 9.7049
Mean episode rew_target_joint_pos_l: 9.0367
Mean episode rew_target_joint_pos_r: 7.1679
      Mean episode rew_termination: -0.0000
    Mean episode rew_torque_limits: -0.0351
          Mean episode rew_torques: -0.1538
 Mean episode rew_tracking_ang_vel: 1.7254
Mean episode rew_tracking_lin_x_vel: 3.2664
Mean episode rew_tracking_lin_y_vel: 2.3819
```

* <https://github.com/engineai-robotics/engineai_legged_gym>
* [5å¤©å¸¦ä½ ä¸Šæ‰‹Isacc gym&RLå­¦ä¹ ](https://gvtdwawnc78.feishu.cn/wiki/EmUWwxp9divnAPkQPsjcY8PunKd)
* [GAMES-105](https://games-105.github.io/)
